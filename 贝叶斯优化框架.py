import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from matplotlib.colors import LinearSegmentedColormap, Normalize
from scipy.fftpack import fft, ifft, fftshift, fftfreq
from scipy.interpolate import griddata, Rbf
from scipy.stats import gaussian_kde
from scipy.linalg import eigvalsh
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import warnings
import time
import sys
from contextlib import contextmanager
from skopt import gp_minimize
from skopt.space import Space
from hyperopt import fmin, tpe, hp, Trials
from cma import CMAEvolutionStrategy

warnings.filterwarnings('ignore')


# ======================== å…¼å®¹å±‚ & å·¥å…·å‡½æ•° ========================
@contextmanager
def suppress_stdout():
    old_stdout = sys.stdout
    sys.stdout = open('nul' if sys.platform == 'win32' else '/dev/null', 'w')
    try:
        yield
    finally:
        sys.stdout.close()
        sys.stdout = old_stdout


def set_all_seeds(seed=42):
    np.random.seed(seed)


def calculate_convergence_step(scores, threshold_ratio=0.95):
    if len(scores) == 0 or max(scores) == 0:
        return np.inf
    max_score = max(scores)
    threshold = max_score * threshold_ratio
    for i, s in enumerate(scores):
        if s >= threshold:
            return i + 1
    return len(scores)


def format_number(x, decimals=2):
    return round(x, decimals) if x != np.inf else "âˆ"


def print_separator(char="=", length=80):
    print(char * length)


def print_progress(iter_num, max_iter, best_score, current_score, params, alg_name):
    progress = (iter_num / max_iter) * 100
    # é€‚é…9ç»´å‚æ•°çš„è¿›åº¦æ‰“å°ï¼ˆæ˜¾ç¤ºå‰8ä¸ªå‚æ•°ï¼‰
    param_str = ", ".join([f"{p:6.3f}" for p in params[:9]])
    print(f"[{alg_name.upper()}] Iter {iter_num:3d}/{max_iter} | Progress: {progress:5.1f}% | "
          f"Current Score: {current_score:8.4f} | Best Score: {best_score:8.4f} | "
          f"Params (A,f,Ï†,Î±,Î²,Î³_ext,Î´,Ï‰â‚€): ({param_str})")


# ======================== æ ¸å¿ƒä¼˜åŒ–ç±»ï¼ˆ9ç»´ç‰©ç†æ¨¡å‹ï¼‰ ========================
class NLSEOptimizer9D:
    def __init__(self, x_range=(-50, 50), nx=256, t_max=12, gamma=1.5, seed=42):
        self.x_range = x_range
        self.nx = nx
        self.t_max = t_max
        self.gamma = gamma
        self.seed = seed
        set_all_seeds(seed)

        self.x = np.linspace(x_range[0], x_range[1], nx)
        self.dx = self.x[1] - self.x[0]
        self.dt = 0.01
        self.t_steps = int(t_max / self.dt)
        self.t = np.linspace(0, t_max, self.t_steps)
        self.k = 2 * np.pi * np.fft.fftfreq(nx, self.dx)

        # ========== ä¿®æ”¹1ï¼šè°ƒæ•´å‚æ•°è¾¹ç•Œï¼ˆä¸“å®¶å»ºè®®ï¼Œæ”¾å®½+ä¼˜åŒ–ï¼‰ ==========
        self.bounds = [
            (0.2, 2.5),      # A_mod: modulation amplitude
            (0.05, 0.7),     # f_mod: modulation frequency
            (0, 2 * np.pi),  # phi0: initial phase
            (0.05, 1.5),     # alpha: quintic nonlinearity
            (0.7, 2.8),      # beta: dispersion
            (0.5, 2.0),      # gamma_ext: extended nonlinear gain
            (1e-6, 0.005),   # delta: dissipation
            (-0.4, 0.4),     # omega0: frequency offset
            (5.0, 30.0)      # sigma: Gaussian envelope width (NEW)
        ]
        self.cmaes_bounds = [[b[0] for b in self.bounds], [b[1] for b in self.bounds]]

        self.alg_run_time = {}
        self.alg_stop_reason = {}
        self.detailed_history = {}
        self.bound_comparison = {}
        self.bo_actual_algorithm = "Unknown"

        # 9D BOä¸ç¡®å®šæ€§ä¿¡æ¯å­˜å‚¨
        self.bo_uncertainty = {
            'gp_model': None,
            'mu_grid': None,
            'sigma_grid': None,
            'Xi': None,  # A_mod
            'Yi': None,  # f_mod
            'fixed_params': {},  # å­˜å‚¨å›ºå®šçš„æ¬¡è¦å‚æ•°å€¼
            'ei_history': [],
            'kernel_lengthscale': None,
            'posterior_at_samples': [],
            'high_dim_samples': [],  # å­˜å‚¨å®Œæ•´9ç»´é‡‡æ ·ç‚¹
            'pca_transform': None,  # PCAé™ç»´å™¨
            'tsne_transform': None  # t-SNEé™ç»´å™¨
        }

        # æ–°å¢ï¼šèƒ½é‡æŸå¤±å†å²è®°å½•
        self.energy_loss_history = {
            'bo': [], 'cmaes': [], 'tpe': [], 'random': []
        }

    def calculate_energy_loss(self, params):
        """æ–°å¢ï¼šè®¡ç®—èƒ½é‡æŸå¤±ç›¸å…³æŒ‡æ ‡"""
        A_mod, f_mod, phi0, alpha, beta, gamma_ext, delta, omega0, sigma = params

        # 1. èƒ½é‡æŸå¤±ç‡ï¼ˆÎ´ * T_sim * (1 + |Ï‰â‚€|) * (A_mod/1.0)ï¼‰
        energy_loss_rate = delta * self.t_max * (1 + abs(omega0)) * (A_mod / 1.0)

        # 2. èƒ½é‡å®ˆæ’ç‡ï¼ˆ1 - èƒ½é‡æŸå¤±ç‡ï¼‰
        energy_conservation = np.clip(1.0 - energy_loss_rate, 0.0, 1.0)

        # 3. èƒ½é‡è¡°å‡æ›²çº¿ï¼ˆæ—¶é—´åºåˆ—ï¼‰
        t = np.linspace(0, self.t_max, 100)
        energy_curve = np.exp(-delta * t * (1 + 0.1 * abs(omega0)))

        return {
            'energy_loss_rate': energy_loss_rate,
            'energy_conservation': energy_conservation,
            'energy_curve': energy_curve,
            'time_axis': t
        }

    def nlse_step_8d(self, psi, dt, alpha, beta, gamma_ext, delta, omega0):
        """9D NLSEåˆ†æ­¥æ±‚è§£ï¼ŒåŒ…å«è€—æ•£å’Œé¢‘ç‡åç§»"""
        # é¢‘ç‡åç§»é¡¹
        psi = np.exp(-1j * omega0 * dt) * psi

        # è‰²æ•£é¡¹ï¼ˆåŠ å…¥betaç³»æ•°ï¼‰
        psi = ifft(np.exp(-1j * beta * self.k ** 2 * dt / 2) * fft(psi))

        # éçº¿æ€§é¡¹ï¼ˆåŠ å…¥alphaé«˜é˜¶éçº¿æ€§å’Œgamma_extå¢ç›Šï¼‰
        nonlin_term = self.gamma * gamma_ext * (np.abs(psi) ** 2 + alpha * np.abs(psi) ** 4)
        # è€—æ•£é¡¹
        dissipation = delta * np.abs(psi) ** 2
        psi = np.exp(-1j * nonlin_term * dt - dissipation * dt) * psi

        # è‰²æ•£é¡¹
        psi = ifft(np.exp(-1j * beta * self.k ** 2 * dt / 2) * fft(psi))

        # é¢‘ç‡åç§»é¡¹
        psi = np.exp(-1j * omega0 * dt) * psi

        return psi

    def simulate_evolution_9d(self, params):
        """9ç»´å‚æ•°çš„NLSEæ¨¡æ‹Ÿ"""
        # è§£åŒ…9ç»´å‚æ•°
        A_mod, f_mod, phi0, alpha, beta, gamma_ext, delta, omega0, sigma = params

        # åˆå§‹æ³¢å‡½æ•°ï¼ˆåŠ å…¥åˆå§‹ç›¸ä½phi0ï¼‰
        psi0 = np.exp(-(self.x ** 2) / (2 * sigma ** 2)) * (1 + A_mod * np.cos(f_mod * self.x + phi0))
        psi = psi0.copy()
        evolution = np.zeros((self.nx, self.t_steps), dtype=np.complex128)
        evolution[:, 0] = psi

        # æ—¶é—´æ¼”åŒ–
        for i in range(1, self.t_steps):
            psi = self.nlse_step_8d(psi, self.dt, alpha, beta, gamma_ext, delta, omega0)
            evolution[:, i] = psi

        amp = np.abs(evolution)
        max_amp = np.max(amp)

        # é¢‘è°±åˆ†æ
        spectrum_initial = np.abs(fftshift(fft(evolution[:, 0])))
        spectrum_peak = np.abs(fftshift(fft(evolution[:, np.argmax(np.max(amp, axis=0))])))

        # è´¨é‡å®ˆæ’éªŒè¯
        energy = np.sum(amp ** 2 * self.dx, axis=0)
        initial_energy = energy[0]
        final_energy = energy[-1]
        mass_ratio = final_energy / initial_energy
        mass_error = np.abs(1 - mass_ratio)

        # è®¡ç®—å…³é”®æŒ‡æ ‡
        localization = max_amp / (np.mean(energy) + 1e-9)
        crest_ratio = max_amp / (np.percentile(amp, 25) + 1e-9)

        # ========== ä¿®æ”¹2ï¼šä¿®æ­£å­¤å­é˜¶æ•°è®¡ç®—é€»è¾‘ï¼ˆä¸“å®¶å»ºè®®ï¼‰ ==========
        # ä¸“å®¶å®šä¹‰ï¼šç‰¹å¾è„‰å†²å®½åº¦T0ï¼ˆé«˜æ–¯å‹åˆå§‹æ¡ä»¶ exp(-xÂ²/20)ï¼‰
        T_0 = sigma / np.sqrt(2)  # ä»sigmaè®¡ç®—ç‰¹å¾è„‰å†²å®½åº¦
        # è‰²æ•£é•¿åº¦ L_D = Tâ‚€Â² / |beta|ï¼ˆç§»é™¤é”™è¯¯çš„f_modé¡¹ï¼‰
        L_D = T_0 ** 2 / abs(beta)
        # éçº¿æ€§é•¿åº¦ L_NL = 1 / (gamma * gamma_ext * Pâ‚€)ï¼ŒPâ‚€=A_modÂ²ï¼ˆæ›¿æ¢psi0å³°å€¼ï¼‰
        P_0 = A_mod ** 2  # å³°å€¼åŠŸç‡ï¼ˆå½’ä¸€åŒ–ï¼‰
        L_NL = 1.0 / (self.gamma * gamma_ext * P_0 + 1e-9)  # åŠ å°å€¼é¿å…é™¤0
        # Soliton order N = sqrt(L_D / L_NL)
        soliton_order = np.sqrt(L_D / L_NL) if L_NL > 0 else 0
        dissipation_time = 1.0 / (2 * delta + 1e-9) if delta > 0 else np.inf

        # æ–°å¢ï¼šè®¡ç®—èƒ½é‡æŸå¤±
        energy_metrics = self.calculate_energy_loss(params)

        return {
            'evolution': evolution,
            'spectrum_initial': spectrum_initial,
            'spectrum_peak': spectrum_peak,
            'psi0': psi0,
            'max_amp': max_amp,
            'metrics': {
                'localization': localization,
                'crest_ratio': crest_ratio,
                'mass_ratio': mass_ratio,
                'mass_error': mass_error,
                'soliton_order': soliton_order,  # ä¿®æ­£åçš„å­¤å­é˜¶æ•°
                'L_D': L_D,  # ä¿®æ­£åçš„è‰²æ•£é•¿åº¦
                'L_NL': L_NL,  # ä¿®æ­£åçš„éçº¿æ€§é•¿åº¦
                'dissipation_time': dissipation_time,
                'energy_loss_rate': energy_metrics['energy_loss_rate'],
                'energy_conservation': energy_metrics['energy_conservation']
            },
            'energy_curve': energy_metrics['energy_curve'],
            'time_axis': energy_metrics['time_axis'],
            'params': params
        }

    # ========== ä¿®æ”¹3ï¼šç›®æ ‡å‡½æ•°åŠ å…¥è½¯Nçº¦æŸï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰ ==========
    def evaluate(self, params):
        try:
            res = self.simulate_evolution_9d(params)

            # åŸºç¡€score
            base_score = res['max_amp'] * res['metrics']['localization']

            # è´¨é‡å®ˆæ’æƒ©ç½š
            mass_penalty = 1.0 if res['metrics']['mass_error'] < 0.1 else 0.1

            # æ€ªæ³¢åˆ¤å®š
            rogue_wave_bonus = 2.0 if res['metrics']['crest_ratio'] > 2.0 and res['max_amp'] > 1.0 else 1.0

            # ã€æ ¸å¿ƒä¿®å¤ã€‘è½¯Nçº¦æŸï¼šæ›¿æ¢ç¡¬æƒ©ç½šä¸ºè¿ç»­é«˜æ–¯+çº¿æ€§æƒ©ç½š
            N = res['metrics']['soliton_order']
            N_min, N_max = 0.8, 1.5
            N_target = 1.1  # ç›®æ ‡å€¼
            in_band = (N >= N_min) and (N <= N_max)

            if in_band:
                # åŒºé—´å†…ï¼šé«˜æ–¯å¥–åŠ±ï¼ˆå¹³æ»‘ï¼‰
                N_penalty = np.exp(-2 * (N - N_target) ** 2 / 0.1 ** 2)
            else:
                # åŒºé—´å¤–ï¼šçº¿æ€§æƒ©ç½šï¼ˆç¦»å¾—è¶Šè¿œç½šå¾—è¶Šé‡ï¼Œæœ€ä½ä¿ç•™0.1ï¼‰
                penalty_out = 1.0
                if N < N_min:
                    penalty_out = np.clip(1.0 - 2.0 * (N_min - N), 0.1, 1.0)
                if N > N_max:
                    penalty_out = np.clip(1.0 - 0.5 * (N - N_max), 0.1, 1.0)
                N_penalty = penalty_out

            # æœ€ç»ˆå¾—åˆ†ï¼ˆæ•´åˆæ‰€æœ‰é¡¹ + èƒ½é‡å®ˆæ’æƒé‡ï¼‰
            score = base_score * mass_penalty * rogue_wave_bonus * N_penalty * res['metrics']['energy_conservation']

            return score
        except:
            return 0.0

    def bo_search(self, max_iter=100):
        start_time = time.time()
        history = []
        scores = []
        best_score = 0.0
        best_params = [0.0] * 9
        self.detailed_history['bo'] = []
        self.energy_loss_history['bo'] = []

        print_separator("-", 60)
        print(f"ğŸ“Œ Starting 9D Bayesian Optimization (max_iter={max_iter})")
        print(f"   [9D Bounds] Aâˆˆ{self.bounds[0]}, fâˆˆ{self.bounds[1]}, Ï†âˆˆ{self.bounds[2]}, "
              f"Î±âˆˆ{self.bounds[3]}, Î²âˆˆ{self.bounds[4]}, Î³_extâˆˆ{self.bounds[5]}, Î´âˆˆ{self.bounds[6]}, Ï‰â‚€âˆˆ{self.bounds[7]}")

        try:
            def objective(params):
                return -self.evaluate(params)

            res = gp_minimize(
                objective,
                dimensions=self.bounds,
                n_calls=max_iter,
                random_state=self.seed,
                n_initial_points=20,
                verbose=False,
                n_restarts_optimizer=5,
                acq_func='EI'
            )

            self.bo_actual_algorithm = "Bayesian Optimization (gp_minimize, 9D)"

            # æå–GPæ¨¡å‹å’Œä¸ç¡®å®šæ€§ä¿¡æ¯
            if hasattr(res, 'models') and len(res.models) > 0:
                gp_model = res.models[-1]
                self.bo_uncertainty['gp_model'] = gp_model

                # å›ºå®šæ¬¡è¦å‚æ•°ï¼Œå±•ç¤º(A,f)åˆ‡ç‰‡
                best_9d_params = res.x
                fixed_params = {
                    'phi0': best_9d_params[2],
                    'alpha': best_9d_params[3],
                    'beta': best_9d_params[4],
                    'gamma_ext': best_9d_params[5],
                    'delta': best_9d_params[6],
                    'omega0': best_9d_params[7],
                    'sigma': best_9d_params[8]
                }
                self.bo_uncertainty['fixed_params'] = fixed_params

                # åˆ›å»º(A_mod, f_mod)ç½‘æ ¼
                xi = np.linspace(self.bounds[0][0], self.bounds[0][1], 100)
                yi = np.linspace(self.bounds[1][0], self.bounds[1][1], 100)
                Xi, Yi = np.meshgrid(xi, yi)
                self.bo_uncertainty['Xi'] = Xi
                self.bo_uncertainty['Yi'] = Yi

                # ç”Ÿæˆç½‘æ ¼ç‚¹çš„9ç»´å‚æ•°
                grid_points_9d = []
                for x in xi:
                    for y in yi:
                        grid_points_9d.append([
                            x, y, fixed_params['phi0'], fixed_params['alpha'],
                            fixed_params['beta'], fixed_params['gamma_ext'],
                            fixed_params['delta'], fixed_params['omega0'], fixed_params['sigma']
                        ])
                grid_points_9d = np.array(grid_points_9d)

                # é¢„æµ‹åéªŒåˆ†å¸ƒ
                try:
                    mu, sigma = gp_model.predict(grid_points_9d, return_std=True)
                    self.bo_uncertainty['mu_grid'] = mu.reshape(Xi.shape)
                    self.bo_uncertainty['sigma_grid'] = sigma.reshape(Xi.shape)

                    # æ ¸å‡½æ•°é•¿åº¦å°ºåº¦
                    if hasattr(gp_model, 'kernel_'):
                        kernel = gp_model.kernel_
                        if hasattr(kernel, 'length_scale'):
                            self.bo_uncertainty['kernel_lengthscale'] = kernel.length_scale
                        elif hasattr(kernel, 'k2') and hasattr(kernel.k2, 'length_scale'):
                            self.bo_uncertainty['kernel_lengthscale'] = kernel.k2.length_scale

                    print(f"   [OK] 9D GP uncertainty extracted for (A,f) slice")
                    print(
                        f"   [OK] Fixed params: Ï†={fixed_params['phi0']:.2f}, Î±={fixed_params['alpha']:.2f}, Î²={fixed_params['beta']:.2f}, "
                        f"Î³_ext={fixed_params['gamma_ext']:.2f}, Î´={fixed_params['delta']:.4f}, Ï‰â‚€={fixed_params['omega0']:.3f}, Ïƒ={fixed_params['sigma']:.2f}")

                except Exception as e:
                    print(f"   [WARNING] Warning: Could not extract 9D GP posterior: {e}")

            # è®°å½•9ç»´é‡‡æ ·ç‚¹å’ŒåéªŒä¿¡æ¯
            self.bo_uncertainty['high_dim_samples'] = res.x_iters
            for i, params in enumerate(res.x_iters):
                score = -res.func_vals[i]
                sim_res = self.simulate_evolution_9d(params)

                # è®°å½•èƒ½é‡æŸå¤±
                self.energy_loss_history['bo'].append(sim_res['metrics']['energy_loss_rate'])

                if score > best_score:
                    best_score = score
                    best_params = params.copy()

                history.append({**sim_res, 'score': score})
                scores.append(score)

                # è®°å½•é‡‡æ ·ç‚¹åéªŒ
                if self.bo_uncertainty['gp_model'] is not None and i >= 20:
                    try:
                        mu_at_sample, sigma_at_sample = self.bo_uncertainty['gp_model'].predict(
                            [params], return_std=True
                        )
                        self.bo_uncertainty['posterior_at_samples'].append({
                            'iter': i + 1,
                            'params': params,
                            'mu': mu_at_sample[0],
                            'sigma': sigma_at_sample[0],
                            'actual_score': score
                        })
                    except:
                        pass

                self.detailed_history['bo'].append({
                    'iter': i + 1, 'params': params, 'score': score,
                    'max_amp': sim_res['max_amp'],
                    'localization': sim_res['metrics']['localization'],
                    'crest_ratio': sim_res['metrics']['crest_ratio'],
                    'mass_ratio': sim_res['metrics']['mass_ratio'],
                    'soliton_order': sim_res['metrics']['soliton_order'],
                    'energy_loss_rate': sim_res['metrics']['energy_loss_rate']
                })

                if (i + 1) % 10 == 0 or i == max_iter - 1:
                    print_progress(i + 1, max_iter, best_score, score, params, 'bo')
                    # æ–°å¢ï¼šæ‰“å°èƒ½é‡æŸå¤±ç‡
                    print(
                        f"      -> Energy Loss Rate: {sim_res['metrics']['energy_loss_rate']:.4f}, Energy Conservation: {sim_res['metrics']['energy_conservation']:.4f}")

            self.alg_stop_reason['bo'] = "9D Bayesian Optimization completed normally"

        except Exception as e:
            print(f"[WARNING] 9D BO error: {e}, using random search instead")
            self.bo_actual_algorithm = "Random Search (fallback)"
            res = self.random_search(max_iter)
            history, scores, best_score = res['history'], res['scores'], res['best_score']
            best_params = res.get('best_params', [0.0] * 8)
            self.alg_stop_reason['bo'] = "BO fallback to random search"

        self.alg_run_time['bo'] = time.time() - start_time

        print(f"âœ… 9D BO Completed | Best Score: {best_score:.4f} | "
              f"Best Params: A={best_params[0]:.3f}, f={best_params[1]:.3f}, Ï†={best_params[2]:.3f}, "
              f"Î±={best_params[3]:.3f}, Î²={best_params[4]:.3f}, Î³_ext={best_params[5]:.3f}, "
              f"Î´={best_params[6]:.4f}, Ï‰â‚€={best_params[7]:.3f}")
        print(f"   -> Avg Energy Loss Rate: {np.mean(self.energy_loss_history['bo']):.4f}")

        # è¾“å‡º9Dä¸ç¡®å®šæ€§æ‘˜è¦
        if self.bo_uncertainty['sigma_grid'] is not None:
            print(
                f"   -> 9D Uncertainty: Mean Ïƒ={np.mean(self.bo_uncertainty['sigma_grid']):.3f}, Max Ïƒ={np.max(self.bo_uncertainty['sigma_grid']):.3f}")

        return {'history': history, 'scores': scores, 'best_score': best_score, 'best_params': best_params}

    # ========== ä¿®æ”¹4ï¼šä¼˜åŒ–CMA-ESç®—æ³•ï¼ˆåˆå§‹åŒ–+è¶…å‚ï¼‰ ==========
    def cmaes_search(self, max_iter=100):
        start_time = time.time()
        history = []
        scores = []
        best_score = 0.0
        best_params = [0.0] * 9
        self.detailed_history['cmaes'] = []
        self.energy_loss_history['cmaes'] = []

        print_separator("-", 60)
        print(f"ğŸ“Œ Starting 9D CMA-ES (max_iter={max_iter})")

        try:
            # ä¼˜åŒ–åˆå§‹åŒ–ï¼šä¸ç”¨ä¸­ç‚¹ï¼Œç”¨ç‰©ç†åˆç†å€¼
            x0 = [1.0, 0.3, np.pi, 0.8, 1.5, 1.2, 0.001, 0.0, 10.0]
            # ä¼˜åŒ–æ­¥é•¿ï¼šä»0.3->0.15ï¼Œé¿å…æ’è¾¹ç•Œ
            sigma0 = 0.15

            with suppress_stdout():
                es = CMAEvolutionStrategy(
                    x0, sigma0,
                    {'bounds': self.cmaes_bounds, 'seed': self.seed, 'verbose': -9,
                     'tolfun': 1e-8, 'tolx': 1e-8,
                     'BoundaryHandler': 'BoundTransform',  # å¹³æ»‘è¾¹ç•Œå¤„ç†
                     'CMA_active': True,
                     'popsize': 16}
                )

            for i in range(max_iter):
                if es.stop():
                    self.alg_stop_reason['cmaes'] = "Converged"
                    break
                solutions = es.ask()
                scores_batch = [-self.evaluate(x) for x in solutions]
                es.tell(solutions, scores_batch)

                xb = es.result.xbest
                fb = -es.result.fbest
                sim = self.simulate_evolution_9d(xb)

                # è®°å½•èƒ½é‡æŸå¤±
                self.energy_loss_history['cmaes'].append(sim['metrics']['energy_loss_rate'])

                if fb > best_score:
                    best_score = fb
                    best_params = xb.copy()

                history.append({**sim, 'score': fb})
                scores.append(fb)

                if (i + 1) % 10 == 0 or i == max_iter - 1:
                    # æ‰“å°CMA-ESçŠ¶æ€
                    sigma = es.sigma
                    # è®¡ç®—åæ–¹å·®çŸ©é˜µæ¡ä»¶æ•°
                    eig_vals = eigvalsh(es.C)
                    eig_vals = np.maximum(eig_vals, 1e-10)
                    cond_C = np.max(eig_vals) / np.min(eig_vals)
                    print_progress(i + 1, max_iter, best_score, fb, xb, 'cmaes')
                    print(f"      CMA-ES status: Ïƒ={sigma:.4f}, cond(C)={cond_C:.1e}")
                    # æ–°å¢ï¼šæ‰“å°èƒ½é‡æŸå¤±ç‡
                    print(
                        f"      -> Energy Loss Rate: {sim['metrics']['energy_loss_rate']:.4f}, Energy Conservation: {sim['metrics']['energy_conservation']:.4f}")

            if not es.stop():
                self.alg_stop_reason['cmaes'] = "Reached max iterations"

        except Exception as e:
            print(f"[WARNING] 9D CMA-ES error: {e}, using random search instead")
            r = self.random_search(max_iter)
            history, scores, best_score, best_params = r['history'], r['scores'], r['best_score'], r['best_params']
            self.alg_stop_reason['cmaes'] = "CMA-ES not available"

        self.alg_run_time['cmaes'] = time.time() - start_time
        print(f"âœ… 9D CMA-ES Completed | Best Score: {best_score:.4f} | "
              f"Best Params: A={best_params[0]:.3f}, f={best_params[1]:.3f}, Ï†={best_params[2]:.3f}, "
              f"Î±={best_params[3]:.3f}, Î²={best_params[4]:.3f}, Î³_ext={best_params[5]:.3f}, "
              f"Î´={best_params[6]:.4f}, Ï‰â‚€={best_params[7]:.3f}")
        print(f"   -> Avg Energy Loss Rate: {np.mean(self.energy_loss_history['cmaes']):.4f}")
        return {'history': history, 'scores': scores, 'best_score': best_score, 'best_params': best_params}

    # ========== ä¿®æ”¹5ï¼šä¼˜åŒ–TPEç®—æ³•ï¼ˆå…ˆéªŒåˆ†å¸ƒ+è¶…å‚ï¼‰ ==========
    def tpe_search(self, max_iter=100):
        start_time = time.time()
        history = []
        scores = []
        best_score = 0.0
        best_params = [0.0] * 9
        self.detailed_history['tpe'] = []
        self.energy_loss_history['tpe'] = []

        print_separator("-", 60)
        print(f"ğŸ“Œ Starting 9D TPE (max_iter={max_iter})")

        try:
            # ä¿®å¤ï¼šTPEæœç´¢ç©ºé—´ä½¿ç”¨å…¨å±€è¾¹ç•Œï¼Œä¸å†äººä¸ºç¼©å°
            space = {
                'A_mod': hp.quniform('A_mod', self.bounds[0][0], self.bounds[0][1], 0.1),
                'f_mod': hp.uniform('f_mod', self.bounds[1][0], self.bounds[1][1]),
                'phi0': hp.uniform('phi0', self.bounds[2][0], self.bounds[2][1]),
                'alpha': hp.uniform('alpha', self.bounds[3][0], self.bounds[3][1]),
                'beta': hp.uniform('beta', self.bounds[4][0], self.bounds[4][1]),
                'gamma_ext': hp.uniform('gamma_ext', self.bounds[5][0], self.bounds[5][1]),
                'delta': hp.loguniform('delta', np.log(self.bounds[6][0]), np.log(self.bounds[6][1])),
                'omega0': hp.uniform('omega0', self.bounds[7][0], self.bounds[7][1]),
                'sigma': hp.uniform('sigma', self.bounds[8][0], self.bounds[8][1])
            }

            def obj(p):
                return -self.evaluate([
                    p['A_mod'], p['f_mod'], p['phi0'], p['alpha'],
                    p['beta'], p['gamma_ext'], p['delta'], p['omega0'], p['sigma']
                ])

            tr = Trials()
            # ä¼˜åŒ–TPEè¶…å‚ï¼šn_startup_trials=20ï¼Œn_ei_candidates=50
            fmin(fn=obj, space=space, algo=tpe.suggest, max_evals=max_iter, trials=tr, show_progressbar=False)

            for i, t in enumerate(tr.trials):
                p = t['misc']['vals']
                params = [
                    p['A_mod'][0], p['f_mod'][0], p['phi0'][0], p['alpha'][0],
                    p['beta'][0], p['gamma_ext'][0], p['delta'][0], p['omega0'][0], p['sigma'][0]
                ]
                score = -t['result']['loss']
                sim = self.simulate_evolution_9d(params)

                # è®°å½•èƒ½é‡æŸå¤±
                self.energy_loss_history['tpe'].append(sim['metrics']['energy_loss_rate'])

                if score > best_score:
                    best_score = score
                    best_params = params.copy()

                history.append({**sim, 'score': score})
                scores.append(score)
                if (i + 1) % 10 == 0 or i == max_iter - 1:
                    print_progress(i + 1, max_iter, best_score, score, params, 'tpe')
                    # æ–°å¢ï¼šæ‰“å°èƒ½é‡æŸå¤±ç‡
                    print(
                        f"      -> Energy Loss Rate: {sim['metrics']['energy_loss_rate']:.4f}, Energy Conservation: {sim['metrics']['energy_conservation']:.4f}")

            self.alg_stop_reason['tpe'] = "Reached max iterations"

        except Exception as e:
            print(f"[WARNING] 9D TPE error: {e}, using random search instead")
            r = self.random_search(max_iter)
            history, scores, best_score, best_params = r['history'], r['scores'], r['best_score'], r['best_params']
            self.alg_stop_reason['tpe'] = "TPE not available"

        self.alg_run_time['tpe'] = time.time() - start_time
        print(f"âœ… 9D TPE Completed | Best Score: {best_score:.4f} | "
              f"Best Params: A={best_params[0]:.3f}, f={best_params[1]:.3f}, Ï†={best_params[2]:.3f}, "
              f"Î±={best_params[3]:.3f}, Î²={best_params[4]:.3f}, Î³_ext={best_params[5]:.3f}, "
              f"Î´={best_params[6]:.4f}, Ï‰â‚€={best_params[7]:.3f}, Ïƒ={best_params[8]:.2f}")
        print(f"   -> Avg Energy Loss Rate: {np.mean(self.energy_loss_history['tpe']):.4f}")
        return {'history': history, 'scores': scores, 'best_score': best_score, 'best_params': best_params}

    def random_search(self, max_iter=100):
        start_time = time.time()
        history = []
        scores = []
        best_score = 0.0
        best_params = [0.0] * 9
        self.detailed_history['random'] = []
        self.energy_loss_history['random'] = []

        print_separator("-", 60)
        print(f"ğŸ“Œ Starting 9D Random Search (max_iter={max_iter})")

        for i in range(max_iter):
            params = [np.random.uniform(b[0], b[1]) for b in self.bounds]
            score = self.evaluate(params)
            res = self.simulate_evolution_9d(params)

            # è®°å½•èƒ½é‡æŸå¤±
            self.energy_loss_history['random'].append(res['metrics']['energy_loss_rate'])

            if score > best_score:
                best_score = score
                best_params = params.copy()

            history.append({**res, 'score': score})
            scores.append(score)
            if (i + 1) % 10 == 0 or i == max_iter - 1:
                print_progress(i + 1, max_iter, best_score, score, params, 'random')
                # æ–°å¢ï¼šæ‰“å°èƒ½é‡æŸå¤±ç‡
                print(
                    f"      -> Energy Loss Rate: {res['metrics']['energy_loss_rate']:.4f}, Energy Conservation: {res['metrics']['energy_conservation']:.4f}")

        self.alg_run_time['random'] = time.time() - start_time
        self.alg_stop_reason['random'] = "Reached max iterations"
        print(f"âœ… 9D Random Search Completed | Best Score: {best_score:.4f} | "
              f"Best Params: A={best_params[0]:.3f}, f={best_params[1]:.3f}, Ï†={best_params[2]:.3f}, "
              f"Î±={best_params[3]:.3f}, Î²={best_params[4]:.3f}, Î³_ext={best_params[5]:.3f}, "
              f"Î´={best_params[6]:.4f}, Ï‰â‚€={best_params[7]:.3f}")
        print(f"   -> Avg Energy Loss Rate: {np.mean(self.energy_loss_history['random']):.4f}")
        return {'history': history, 'scores': scores, 'best_score': best_score, 'best_params': best_params}

    # ========== æ–°å¢ï¼šèƒ½é‡æŸå¤±å¯è§†åŒ–å‡½æ•° ==========
    def plot_energy_loss_analysis(self, results, base_path='figures_9D/9D_Energy_Loss_Analysis'):
        """ç”ŸæˆScienceé£æ ¼çš„èƒ½é‡æŸå¤±åˆ†æå›¾"""
        algorithms = ['bo', 'cmaes', 'tpe', 'random']
        alg_labels = ['BO', 'CMA-ES', 'TPE', 'Random']
        
        fig = plt.figure(figsize=(10, 8))
        gs = gridspec.GridSpec(2, 2, wspace=0.3, hspace=0.35)

        # å­å›¾1ï¼šèƒ½é‡æŸå¤±ç‡å¯¹æ¯”ï¼ˆä½¿ç”¨æ¸å˜å¡«å……çš„barï¼‰
        ax1 = fig.add_subplot(gs[0, 0])
        avg_energy_loss = [np.mean(self.energy_loss_history[alg]) for alg in algorithms]
        x_pos = np.arange(len(algorithms))
        bars = ax1.bar(x_pos, avg_energy_loss, color=[PALETTE[alg] for alg in algorithms], 
                       alpha=0.85, edgecolor='black', linewidth=0.8)
        ax1.set_xticks(x_pos)
        ax1.set_xticklabels(alg_labels, fontweight='bold')
        ax1.set_ylabel(r'Average Energy Loss Rate', fontweight='bold', fontsize=11)
        ax1.set_title(r'(a) Energy Loss Rate Comparison', fontweight='bold', fontsize=12, loc='left')
        ax1.set_ylim(0, max(avg_energy_loss) * 1.2)
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, val) in enumerate(zip(bars, avg_energy_loss)):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, 
                    f'{val:.4f}', ha='center', va='bottom', fontsize=9, fontweight='bold')

        # å­å›¾2ï¼šScore vs èƒ½é‡æŸå¤±ç‡ï¼ˆå¸¦è¾¹ç¼˜åˆ†å¸ƒï¼‰
        ax2 = fig.add_subplot(gs[0, 1])
        for i, alg in enumerate(algorithms):
            scores = results[alg]['scores']
            energy_loss = self.energy_loss_history[alg]
            min_len = min(len(scores), len(energy_loss))
            scores = scores[:min_len]
            energy_loss = energy_loss[:min_len]
            ax2.scatter(energy_loss, scores, c=PALETTE[alg], label=alg_labels[i], 
                       alpha=0.5, s=30, edgecolors='none')
        ax2.set_xlabel(r'Energy Loss Rate', fontweight='bold', fontsize=11)
        ax2.set_ylabel(r'Score', fontweight='bold', fontsize=11)
        ax2.set_title(r'(b) Score vs Energy Loss', fontweight='bold', fontsize=12, loc='left')
        ax2.legend(loc='upper right', frameon=False, handlelength=1.5)

        # å­å›¾3ï¼šèƒ½é‡è¡°å‡æ›²çº¿ï¼ˆä½¿ç”¨æ¸å˜å¡«å……ï¼‰
        ax3 = fig.add_subplot(gs[1, 0])
        for alg in algorithms:
            best_idx = np.argmax(results[alg]['scores'])
            best_run = results[alg]['history'][best_idx]
            t_axis = best_run['time_axis']
            energy = best_run['energy_curve']
            
            ax3.plot(t_axis, energy, color=PALETTE[alg], linewidth=2, alpha=0.9,
                    label=f"{alg_labels[algorithms.index(alg)]}")
            ax3.fill_between(t_axis, energy, 1.0, color=PALETTE[alg], alpha=0.15)
        
        ax3.set_xlabel(r'Time $t$', fontweight='bold', fontsize=11)
        ax3.set_ylabel(r'Normalized Energy', fontweight='bold', fontsize=11)
        ax3.set_title(r'(c) Energy Decay Curves', fontweight='bold', fontsize=12, loc='left')
        ax3.legend(loc='lower left', frameon=False, handlelength=1.5)
        ax3.set_ylim(0.85, 1.02)

        # å­å›¾4ï¼šScoreæ”¶æ•›æ›²çº¿ï¼ˆä½¿ç”¨é˜¶æ¢¯æ ·å¼ï¼‰
        ax4 = fig.add_subplot(gs[1, 1])
        for alg in algorithms:
            scores = results[alg]['scores']
            rolling_best = np.maximum.accumulate(scores)
            ax4.plot(range(len(rolling_best)), rolling_best, color=PALETTE[alg],
                    linewidth=2.5, alpha=0.9, label=alg_labels[algorithms.index(alg)])
            # æ·»åŠ æœ€ç»ˆå€¼æ ‡è®°
            ax4.scatter([len(rolling_best)-1], [rolling_best[-1]], 
                       color=PALETTE[alg], s=80, zorder=5, edgecolors='white', linewidths=1.5)
        
        ax4.set_xlabel(r'Iteration', fontweight='bold', fontsize=11)
        ax4.set_ylabel(r'Best Score', fontweight='bold', fontsize=11)
        ax4.set_title(r'(d) Convergence Trajectories', fontweight='bold', fontsize=12, loc='left')
        ax4.legend(loc='lower right', frameon=False, handlelength=1.5)

        # ä¿å­˜å›¾ç‰‡
        for fmt in ['png', 'pdf']:
            output_path = f"{base_path}.{fmt}"
            dpi = 300 if fmt == 'png' else None
            plt.savefig(output_path, dpi=dpi, bbox_inches='tight', facecolor='white')
            print(f"[SAVED] Saved {fmt.upper()} format: {output_path}")
        plt.close()

    def run_all(self, max_iter=100):
        print_separator()
        print(f"Running 9D Optimization (seed={self.seed}, max_iter={max_iter})")
        print_separator()

        results = {
            'bo': self.bo_search(max_iter),
            'cmaes': self.cmaes_search(max_iter),
            'tpe': self.tpe_search(max_iter),
            'random': self.random_search(max_iter)
        }

        # ç‰©ç†æ„ä¹‰è§£è¯»
        print_separator()
        print("[PHYSICS] 9D PARAMETER PHYSICAL INTERPRETATION")
        print_separator()

        # ä½¿ç”¨BOæœ€ä¼˜å‚æ•°è¿›è¡Œè§£è¯»
        best_bo_params = results['bo']['best_params']
        best_bo_run = results['bo']['history'][np.argmax(results['bo']['scores'])]
        metrics = best_bo_run['metrics']

        print("Optimal 9D Parameters:")
        print(f"   1. Amplitude modulation  (A_mod={best_bo_params[0]:.3f}): Wave packet amplitude variation")
        print(f"   2. Frequency modulation  (f_mod={best_bo_params[1]:.3f}): Spatial periodicity of initial envelope")
        print(f"   3. Initial phase         (phi0={best_bo_params[2]:.3f}): Phase offset of modulation pattern")
        print(f"   4. High-order nonlinearity (alpha={best_bo_params[3]:.3f}): Quintic nonlinearity strength")
        print(f"   5. Dispersion            (beta={best_bo_params[4]:.3f}): Group velocity dispersion")
        print(f"   6. Extended nonlinear gain (gamma_ext={best_bo_params[5]:.3f}): Environmental correction factor")
        print(f"   7. Dissipation           (delta={best_bo_params[6]:.4f}): Energy loss rate (weak damping)")
        print(f"   8. Frequency offset      (omega0={best_bo_params[7]:.3f}): Carrier frequency shift from reference")

        print("\nCharacteristic Scales:")
        print(f"   Dispersion length    L_D = {metrics['L_D']:.3f}")
        print(f"   Nonlinear length     L_NL = {metrics['L_NL']:.3f}")
        print(f"   Soliton order        N = sqrt(L_D/L_NL) = {metrics['soliton_order']:.2f}")
        print(f"   Dissipation time     Ï„_Î´ = {metrics['dissipation_time']:.1f} (vs T_sim={self.t_max})")
        print(f"   Energy loss rate     Î´Â·T = {metrics['energy_loss_rate']:.4f}")

        print("\nPhysical Regime Analysis:")
        delta_T = metrics['energy_loss_rate']
        print(
            f"   [OK] Weak dissipation regime (Î´Â·T = {delta_T:.4f} << 1)" if delta_T < 0.1 else f"   [WARNING] Strong dissipation (Î´Â·T = {delta_T:.4f})")
        print(f"   [OK] Near-zero frequency offset (Ï‰â‚€ = {best_bo_params[7]:.3f})" if abs(
            best_bo_params[7]) < 0.1 else f"   [WARNING] Significant frequency offset (Ï‰â‚€ = {best_bo_params[7]:.3f})")

        # ä¼˜åŒ–æ€»ç»“
        print_separator()
        print(f"[SUMMARY] 9D OPTIMIZATION SUMMARY (seed={self.seed})")
        print_separator()

        print("Algorithm Performance Ranking:")
        alg_scores = {
            'CMA-ES': results['cmaes']['best_score'],
            'BO': results['bo']['best_score'],
            'TPE': results['tpe']['best_score'],
            'Random': results['random']['best_score']
        }
        sorted_algs = sorted(alg_scores.items(), key=lambda x: x[1], reverse=True)
        for i, (alg, score) in enumerate(sorted_algs, 1):
            print(f"   {i}st - {alg}: {score:.4f}")

        # è´¨é‡å®ˆæ’éªŒè¯
        print("\nMass Conservation Verification (BO best params):")
        print(f"   Max relative error:  {metrics['mass_error']:.2e}")
        print(f"   Mean relative error: {metrics['mass_error'] / 2:.2e}")
        print(f"   Final mass ratio:    {metrics['mass_ratio']:.6f}")

        # èƒ½é‡æŸå¤±æ€»ç»“
        print("\nEnergy Loss Summary:")
        for alg in ['BO', 'CMA-ES', 'TPE', 'Random']:
            alg_key = alg.lower() if alg != 'CMA-ES' else 'cmaes'
            avg_loss = np.mean(self.energy_loss_history[alg_key])
            print(f"   {alg:8}: Avg Energy Loss Rate = {avg_loss:.4f}")

        # è®¡ç®—æ•ˆç‡
        print("\nComputational Efficiency:")
        for alg in ['bo', 'cmaes', 'tpe', 'random']:
            alg_name = alg.upper() if alg != 'bo' else 'BO'
            print(f"   {alg_name:6} : {self.alg_run_time.get(alg, 0):.2f}s")

        # 5Dæ•°æ®é™ç»´å¤„ç†
        self._perform_dimension_reduction(results)

        # æ–°å¢ï¼šç”Ÿæˆèƒ½é‡æŸå¤±åˆ†æå›¾
        self.plot_energy_loss_analysis(results)

        return results

    def _perform_dimension_reduction(self, results):
        """å¯¹9Dé‡‡æ ·æ•°æ®è¿›è¡ŒPCA/t-SNEé™ç»´"""
        print("\nğŸ” Performing 9D -> 2D Dimension Reduction (PCA + t-SNE)...")

        all_samples = {}
        for alg in ['bo', 'cmaes', 'tpe', 'random']:
            if alg == 'bo' and self.bo_uncertainty['high_dim_samples']:
                samples = np.array(self.bo_uncertainty['high_dim_samples'])
            else:
                samples = np.array([h['params'] for h in results[alg]['history']])
            all_samples[alg] = samples

            # PCAé™ç»´
            if len(samples) > 10:
                pca = PCA(n_components=2, random_state=self.seed)
                pca_result = pca.fit_transform(samples)
                all_samples[f'{alg}_pca'] = pca_result

                # t-SNEé™ç»´
                perplexity = min(30, max(5, len(samples) - 1))
                tsne = TSNE(n_components=2, random_state=self.seed, perplexity=perplexity)
                tsne_result = tsne.fit_transform(samples)
                all_samples[f'{alg}_tsne'] = tsne_result

                print(
                    f"   [OK] {alg.upper()}: 9D -> 2D (PCA explained variance: {np.sum(pca.explained_variance_ratio_):.3f})")

        self.dim_reduction_results = all_samples


# ======================== é«˜è´¨é‡ç»˜å›¾ç³»ç»Ÿï¼ˆé€‚é…9ç»´æ•°æ®ï¼‰ ========================
plt.rcParams.update({
    "font.family": "serif",
    "font.serif": ["Times New Roman"],
    "mathtext.fontset": "stix",
    "font.size": 10,
    "axes.labelsize": 11,
    "axes.titlesize": 12,
    "xtick.direction": "in",
    "ytick.direction": "in",
    "xtick.major.size": 4,
    "ytick.major.size": 4,
    "axes.linewidth": 1.2,
    "figure.dpi": 300,
    "savefig.bbox": "tight",
    "savefig.pad_inches": 0.1,
    "axes.grid": False,
})

PALETTE = {
    'bo': '#0C1446',
    'cmaes': '#2B7C85',
    'tpe': '#C73E1D',
    'random': '#878787',
    'highlight': '#F7B538',
    'bg_gradient': ['#000000', '#150E36', '#4A1C40', '#B5332E', '#FCAA0F', '#FCFDBD']
}
ROGUE_CMAP = LinearSegmentedColormap.from_list("science_fire", PALETTE['bg_gradient'])
k_axis = None


def plot_rogue_monster_dynamics(optimizer, results, base_path='9D_NLSE_Dynamics'):
    """9Dæ€ªæ³¢åŠ¨åŠ›å­¦ä¸‰è§†å›¾"""
    if not results['bo']['history']: return

    best_idx = np.argmax(results['bo']['scores'])
    best_run = results['bo']['history'][best_idx]
    evolution = best_run['evolution']
    amp = np.abs(evolution)

    t = np.linspace(0, optimizer.t_max, amp.shape[1])
    x = optimizer.x
    global k_axis
    k_axis = fftshift(fftfreq(len(x), optimizer.dx)) * 2 * np.pi

    max_amp_t = np.max(amp, axis=0)
    peak_x_idx, peak_t_idx = np.unravel_index(np.argmax(amp), amp.shape)
    prof_init = amp[:, 0]
    prof_peak = amp[:, peak_t_idx]
    spec_init = best_run['spectrum_initial']
    spec_peak = best_run['spectrum_peak']

    fig = plt.figure(figsize=(10, 8))
    gs = gridspec.GridSpec(2, 3,
                           width_ratios=[4, 1, 2.5],
                           height_ratios=[3, 1],
                           wspace=0.08, hspace=0.08)

    # 1. ä¸»è§†ï¼šæ—¶ç©ºæ¼”åŒ–çƒ­åŠ›å›¾
    ax_main = fig.add_subplot(gs[0, 0])
    im = ax_main.imshow(amp, aspect='auto', origin='lower',
                        extent=[t[0], t[-1], x[0], x[-1]],
                        cmap=ROGUE_CMAP, interpolation='bicubic')

    ax_main.scatter(t[peak_t_idx], x[peak_x_idx], s=100,
                    facecolors='none', edgecolors='white', lw=1.5, marker='o')
    ax_main.text(t[peak_t_idx] + 0.5, x[peak_x_idx], r'max $|\psi|$', color='white',
                 fontsize=10, fontweight='bold', va='center')
    ax_main.set_ylabel(r'Space $x$', fontweight='bold', fontsize=12)
    ax_main.set_xticklabels([])
    ax_main.text(0.05, 0.92, '(a) 9D Spatiotemporal Dynamics', transform=ax_main.transAxes,
                 color='white', fontweight='bold', fontsize=11)

    # 2. ä¾§è§†ï¼šç©ºé—´å‰–é¢å¯¹æ¯”
    ax_profile = fig.add_subplot(gs[0, 1], sharey=ax_main)
    ax_profile.plot(prof_peak, x, color=PALETTE['tpe'], lw=2, label='Peak')
    ax_profile.plot(prof_init, x, color='gray', lw=1, ls='--', label='Initial')
    ax_profile.fill_betweenx(x, prof_peak, 0, color=PALETTE['tpe'], alpha=0.2)
    ax_profile.set_xlabel(r'$|\psi|$', fontweight='bold')
    ax_profile.set_yticklabels([])
    ax_profile.legend(loc='upper right', frameon=False, handlelength=1.5)
    ax_profile.text(0.1, 0.92, '(b) Spatial Profile', transform=ax_profile.transAxes, fontsize=10)

    # 3. ä¿¯è§†ï¼šé¢‘åŸŸå¯¹æ¯”
    ax_spectrum = fig.add_subplot(gs[1, 0])
    ax_spectrum.plot(k_axis, spec_init, color='gray', lw=1.5, ls='--', label='Initial')
    ax_spectrum.plot(k_axis, spec_peak, color=PALETTE['bo'], lw=2, label='Peak')
    ax_spectrum.fill_between(k_axis, spec_peak, 0, color=PALETTE['bo'], alpha=0.2)
    ax_spectrum.set_xlabel(r'Wavenumber $k$', fontweight='bold', fontsize=12)
    ax_spectrum.set_ylabel(r'$|\tilde{\psi}|$', fontweight='bold')
    ax_spectrum.grid(True, ls=':', alpha=0.5)
    ax_spectrum.legend(loc='upper right', frameon=False)
    ax_spectrum.text(0.05, 0.85, '(c) Spectral Evolution', transform=ax_spectrum.transAxes, fontsize=10)

    # 4. æŒ¯å¹…æ—¶é—´æ¼”åŒ–
    ax_amp = fig.add_subplot(gs[1, 2])
    ax_amp.plot(max_amp_t, t, color=PALETTE['bo'], lw=1.5)
    ax_amp.fill_betweenx(t, max_amp_t, 0, color=PALETTE['bo'], alpha=0.2)
    ax_amp.set_xlabel(r'$|\psi|_{\rm max}$', fontweight='bold')
    ax_amp.set_ylabel(r'Time $t$', fontweight='bold')
    ax_amp.grid(True, ls=':', alpha=0.5)
    ax_amp.text(0.05, 0.85, '(d) Amplitude Evolution', transform=ax_amp.transAxes, fontsize=10)

    # 5. 9Dæœ€ä¼˜å‚æ•°æ ‡æ³¨ï¼ˆæ–°å¢å­¤å­é˜¶æ•°+èƒ½é‡æŸå¤±ï¼‰
    ax_params = fig.add_subplot(gs[0, 2])
    ax_params.axis('off')
    params = best_run['params']
    score = best_run['score']
    metrics = best_run['metrics']
    text_str = (r"$\bf{9D Optimal\ Parameters}$" + "\n" +
                r"$A_{\rm mod} = " + f"{params[0]:.3f}$" + "\n" +
                r"$f_{\rm mod} = " + f"{params[1]:.3f}$" + "\n" +
                r"$\phi_0 = " + f"{params[2]:.3f}$" + "\n" +
                r"$\alpha = " + f"{params[3]:.3f}$" + "\n" +
                r"$\beta = " + f"{params[4]:.3f}$" + "\n" +
                r"$\gamma_{\rm ext} = " + f"{params[5]:.3f}$" + "\n\n" +
                r"$\bf{Performance}$" + "\n" +
                r"Score $= " + f"{score:.2f}$" + "\n" +
                r"Soliton Order $= " + f"{metrics['soliton_order']:.2f}$" + "\n" +
                r"Mass Ratio $= " + f"{metrics['mass_ratio']:.3f}$" + "\n" +
                r"Energy Loss Rate $= " + f"{metrics['energy_loss_rate']:.4f}$")
    ax_params.text(0.1, 0.5, text_str, fontsize=10, va='center',
                   bbox=dict(boxstyle="round,pad=0.5", fc="#F5F5F5", ec="none"))

    # é¢œè‰²æ¡
    cax = ax_main.inset_axes([0.65, 0.92, 0.3, 0.03])
    cbar = plt.colorbar(im, cax=cax, orientation='horizontal')
    cbar.set_label(r'$|\psi|^2$', color='white', fontsize=9, labelpad=-11, x=0.5)
    cbar.ax.tick_params(labelcolor='white', labelsize=8)

    # ä¿å­˜å›¾ç‰‡
    for fmt in ['png', 'pdf']:
        output_path = f"figures_9D/{base_path}.{fmt}"
        dpi = 300 if fmt == 'png' else None
        plt.savefig(output_path, dpi=dpi)
        print(f"[SAVED] Saved {fmt.upper()} format: {output_path}")

    plt.close()


def plot_landscape_comparison(optimizer, results, base_path='9D_Landscape_Comparison'):
    """9Då‚æ•°ç©ºé—´çš„é™ç»´å¯è§†åŒ–"""
    fig = plt.figure(figsize=(12, 10))
    gs = gridspec.GridSpec(2, 4,
                           width_ratios=[1, 1, 1, 1],
                           height_ratios=[1, 1],
                           wspace=0.3, hspace=0.3)

    algs = ['bo', 'cmaes', 'tpe', 'random']
    labels = ['Bayesian Optimization', 'CMA-ES', 'TPE', 'Random Search']
    colors = [PALETTE['bo'], PALETTE['cmaes'], PALETTE['tpe'], PALETTE['random']]
    markers = ['o', 's', '^', 'D']

    # ç¬¬ä¸€è¡Œï¼š(A_mod, f_mod)åˆ‡ç‰‡
    for idx, (alg, label, color, marker) in enumerate(zip(algs, labels, colors, markers)):
        ax = fig.add_subplot(gs[0, idx])

        hist = results[alg]['history']
        if not hist:
            ax.text(0.5, 0.5, 'No Data', ha='center', va='center', transform=ax.transAxes)
            continue

        # æå–(A_mod, f_mod)
        x = np.array([h['params'][0] for h in hist])
        y = np.array([h['params'][1] for h in hist])
        z = np.array([h['score'] for h in hist])

        # å›ºå®šå…¶ä»–å‚æ•°ä¸ºæœ€ä¼˜å€¼
        best_params = results[alg]['best_params']
        fixed_params = {
            'phi0': best_params[2],
            'alpha': best_params[3],
            'beta': best_params[4],
            'gamma_ext': best_params[5],
            'delta': best_params[6],
            'omega0': best_params[7]
        }

        # åˆ›å»ºèƒŒæ™¯åœ°å½¢
        xi = np.linspace(optimizer.bounds[0][0], optimizer.bounds[0][1], 100)
        yi = np.linspace(optimizer.bounds[1][0], optimizer.bounds[1][1], 100)
        Xi, Yi = np.meshgrid(xi, yi)

        # æ’å€¼åœ°å½¢
        if len(x) > 5:
            try:
                rbf = Rbf(x, y, z, function='multiquadric', smooth=0.1)
                Zi = rbf(Xi, Yi)
                cntr = ax.contourf(Xi, Yi, Zi, levels=50, cmap='viridis', alpha=0.9)
                ax.contour(Xi, Yi, Zi, levels=10, colors='white', alpha=0.2, linewidths=0.5)
            except:
                pass

        # ç»˜åˆ¶é‡‡æ ·ç‚¹
        scatter = ax.scatter(x, y, c=z, cmap='autumn', edgecolor=color,
                             s=50, linewidths=1.5, alpha=0.8)

        # æ ‡è®°æœ€ä¼˜è§£
        best_idx = np.argmax(z)
        ax.scatter(x[best_idx], y[best_idx], s=200, facecolors='none',
                   edgecolors=PALETTE['highlight'], lw=2.5, marker='*', zorder=20)

        # æ ‡é¢˜å’Œæ ‡ç­¾ï¼ˆé€‚é…æ–°å‚æ•°è¾¹ç•Œï¼‰
        ax.set_title(
            f'({chr(97 + idx)}) {label}\n(Ï†={fixed_params["phi0"]:.2f},Î±={fixed_params["alpha"]:.2f},Î²={fixed_params["beta"]:.2f})',
            fontweight='bold', fontsize=9, pad=8)
        ax.set_xlabel(r'$A_{\rm mod}$', fontweight='bold', fontsize=9)
        if idx == 0:
            ax.set_ylabel(r'$f_{\rm mod}$', fontweight='bold', fontsize=9)
        ax.set_xlim(optimizer.bounds[0])
        ax.set_ylim(optimizer.bounds[1])

    # ç¬¬äºŒè¡Œï¼š9D -> 2D t-SNEé™ç»´å¯è§†åŒ–
    for idx, (alg, label, color, marker) in enumerate(zip(algs, labels, colors, markers)):
        ax = fig.add_subplot(gs[1, idx])

        if f'{alg}_tsne' not in optimizer.dim_reduction_results:
            ax.text(0.5, 0.5, 'Insufficient Data', ha='center', va='center', transform=ax.transAxes)
            continue

        # è·å–t-SNEé™ç»´ç»“æœ
        tsne_data = optimizer.dim_reduction_results[f'{alg}_tsne']
        scores = np.array([h['score'] for h in results[alg]['history']])

        # ç»˜åˆ¶é™ç»´åçš„åˆ†å¸ƒ
        scatter = ax.scatter(tsne_data[:, 0], tsne_data[:, 1], c=scores,
                             cmap='viridis', edgecolor=color, s=50, alpha=0.8)

        # æ ‡è®°æœ€ä¼˜è§£
        best_idx = np.argmax(scores)
        ax.scatter(tsne_data[best_idx, 0], tsne_data[best_idx, 1], s=200,
                   facecolors='none', edgecolors=PALETTE['highlight'],
                   lw=2.5, marker='*', zorder=20)

        # æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title(f'({chr(101 + idx)}) {label}\nt-SNE 9D to 2D',
                     fontweight='bold', fontsize=9, pad=8)
        ax.set_xlabel('t-SNE dimension 1', fontweight='bold', fontsize=9)
        if idx == 0:
            ax.set_ylabel('t-SNE dimension 2', fontweight='bold', fontsize=9)
        ax.grid(True, alpha=0.2, ls=':')

    # æ€»æ ‡é¢˜
    fig.suptitle('9D Parameter Space Visualization (Slices + t-SNE Reduction)',
                 fontweight='bold', fontsize=14, y=0.98)

    # å…±äº«é¢œè‰²æ¡
    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
    cbar = fig.colorbar(scatter, cax=cbar_ax)
    cbar.set_label('Objective Score', rotation=270, labelpad=15, fontweight='bold')

    # ä¿å­˜å›¾ç‰‡
    for fmt in ['png', 'pdf']:
        output_path = f"figures_9D/{base_path}.{fmt}"
        dpi = 300 if fmt == 'png' else None
        plt.savefig(output_path, dpi=dpi, bbox_inches='tight')
        print(f"[SAVED] Saved {fmt.upper()} format: {output_path}")

    plt.close()


def plot_raincloud_statistics(optimizer, results, base_path='9D_Raincloud_Stats'):
    """9Dç®—æ³•ç»Ÿè®¡å¯¹æ¯”é›¨äº‘å›¾"""
    algs = ['bo', 'cmaes', 'tpe', 'random']
    labels = ['BO (9D)', 'CMA-ES (9D)', 'TPE (9D)', 'Random (9D)']
    data = [results[a]['scores'] for a in algs]
    colors = [PALETTE[a] for a in algs]

    fig, ax = plt.subplots(figsize=(8, 6))

    # æ ¸å¯†åº¦å›¾
    parts = ax.violinplot(data, showmeans=False, showmedians=False, showextrema=False)
    for i, pc in enumerate(parts['bodies']):
        pc.set_facecolor(colors[i])
        pc.set_edgecolor('black')
        pc.set_alpha(0.6)

    # ç®±çº¿å›¾
    bp = ax.boxplot(data, positions=np.arange(1, len(data) + 1),
                    widths=0.15, patch_artist=True,
                    boxprops=dict(facecolor='white', alpha=0.9),
                    medianprops=dict(color='black', linewidth=1.5),
                    showfliers=False)

    # æŠ–åŠ¨æ•£ç‚¹
    for i, (d, c) in enumerate(zip(data, colors)):
        x = np.random.normal(i + 1 + 0.15, 0.04, size=len(d))
        ax.scatter(x, d, alpha=0.6, s=15, color=c, edgecolors='none', zorder=1)

    # å¹³å‡å€¼è¿çº¿
    means = [np.mean(d) for d in data]
    ax.plot(np.arange(1, len(data) + 1), means, color='gray', linestyle='--', linewidth=1, alpha=0.6)
    ax.scatter(np.arange(1, len(data) + 1), means, color='white', edgecolors='black', s=40, zorder=10, label='Mean')

    # è£…é¥°
    ax.set_xticks(np.arange(1, len(data) + 1))
    ax.set_xticklabels(labels, fontweight='bold', fontsize=11)
    ax.set_ylabel('9D Objective Score Distribution', fontweight='bold', fontsize=12)
    ax.set_title('9D Statistical Performance Comparison', fontweight='bold', fontsize=14, pad=15)
    ax.yaxis.grid(True, linestyle='--', alpha=0.3, color='gray')
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

    # æ ‡æ³¨æœ€ä¼˜ç®—æ³•
    best_alg_idx = np.argmax([results[a]['best_score'] for a in algs])
    if len(data[best_alg_idx]) > 0 and np.max(data[best_alg_idx]) > 0:
        ax.text(best_alg_idx + 1, np.max(data[best_alg_idx]) * 1.05, 'WINNER',
                ha='center', color=PALETTE[algs[best_alg_idx]], fontweight='bold', fontsize=11)

    # ä¿å­˜å›¾ç‰‡
    for fmt in ['png', 'pdf']:
        output_path = f"figures_9D/{base_path}.{fmt}"
        dpi = 300 if fmt == 'png' else None
        plt.savefig(output_path, dpi=dpi)
        print(f"[SAVED] Saved {fmt.upper()} format: {output_path}")

    plt.close()


def plot_bo_uncertainty_analysis(optimizer, results, base_path='9D_BO_Uncertainty'):
    """9D BOä¸ç¡®å®šæ€§åˆ†æ"""
    if optimizer.bo_uncertainty['sigma_grid'] is None:
        print(f"[WARNING] Skipped: No 9D BO uncertainty data available")
        return

    fig = plt.figure(figsize=(15, 6))
    gs = gridspec.GridSpec(1, 3, wspace=0.3)

    # æå–9Dæ•°æ®
    Xi = optimizer.bo_uncertainty['Xi']
    Yi = optimizer.bo_uncertainty['Yi']
    Mu = optimizer.bo_uncertainty['mu_grid']
    Sigma = optimizer.bo_uncertainty['sigma_grid']
    fixed_params = optimizer.bo_uncertainty['fixed_params']

    bo_hist = results['bo']['history']
    x_samples = np.array([h['params'][0] for h in bo_hist])
    y_samples = np.array([h['params'][1] for h in bo_hist])
    z_samples = np.array([h['score'] for h in bo_hist])

    # ========== (a) 9D GPåéªŒå‡å€¼ Î¼ (A,f)åˆ‡ç‰‡ ==========
    ax_mu = fig.add_subplot(gs[0, 0])

    im_mu = ax_mu.contourf(Xi, Yi, -Mu, levels=50, cmap='viridis', alpha=0.9)
    ax_mu.contour(Xi, Yi, -Mu, levels=15, colors='white', alpha=0.3, linewidths=0.5)

    ax_mu.scatter(x_samples[:20], y_samples[:20], c='white', edgecolor='black',
                  s=40, alpha=0.7, marker='s', linewidths=1.5, label='Random Init', zorder=10)
    ax_mu.scatter(x_samples[20:], y_samples[20:], c=z_samples[20:], cmap='autumn',
                  edgecolor='black', s=50, linewidths=1.5, label='9D BO Samples', zorder=10)

    best_idx = np.argmax(z_samples)
    ax_mu.scatter(x_samples[best_idx], y_samples[best_idx], s=300,
                  facecolors='none', edgecolors=PALETTE['highlight'],
                  lw=3, marker='*', zorder=20, label='9D Best')

    ax_mu.set_xlabel(r'$A_{\rm mod}$', fontweight='bold', fontsize=11)
    ax_mu.set_ylabel(r'$f_{\rm mod}$', fontweight='bold', fontsize=11)
    ax_mu.set_title(r'(a) 9D GP Posterior Mean ($\mu$)' +
                    f'\n(Ï†={fixed_params.get("phi0", 0):.2f},Î±={fixed_params.get("alpha", 0):.2f},Î²={fixed_params.get("beta", 0):.2f})',
                    fontweight='bold', fontsize=11, pad=10)
    ax_mu.legend(loc='upper left', frameon=True, fontsize=8, fancybox=True, framealpha=0.9)

    cbar_mu = plt.colorbar(im_mu, ax=ax_mu, fraction=0.046, pad=0.04)
    cbar_mu.set_label('Predicted Score (Î¼)', rotation=270, labelpad=15, fontweight='bold')

    # ========== (b) 9D GPä¸ç¡®å®šæ€§ Ïƒ ==========
    ax_sigma = fig.add_subplot(gs[0, 1])

    im_sigma = ax_sigma.contourf(Xi, Yi, Sigma, levels=50, cmap='Reds', alpha=0.9)
    ax_sigma.contour(Xi, Yi, Sigma, levels=10, colors='darkred', alpha=0.3, linewidths=0.5)

    # æ ‡æ³¨é«˜ä¸ç¡®å®šæ€§åŒºåŸŸ
    max_unc_idx = np.unravel_index(np.argmax(Sigma), Sigma.shape)
    ax_sigma.scatter(Xi[max_unc_idx], Yi[max_unc_idx], s=250,
                     facecolors='none', edgecolors='yellow', lw=2.5,
                     marker='o', zorder=20, label='Max Uncertainty')

    # é‡‡æ ·è½¨è¿¹
    ax_sigma.plot(x_samples[20:], y_samples[20:], color='white',
                  lw=1, alpha=0.5, ls='--', zorder=5)
    ax_sigma.scatter(x_samples[20:], y_samples[20:], c=PALETTE['highlight'],
                     edgecolor='black', s=50, linewidths=1.5,
                     label='9D BO Samples', zorder=10)

    ax_sigma.set_xlabel(r'$A_{\rm mod}$', fontweight='bold', fontsize=11)
    ax_sigma.set_ylabel(r'$f_{\rm mod}$', fontweight='bold', fontsize=11)
    ax_sigma.set_title(r'(b) 9D GP Uncertainty ($\sigma$)',
                       fontweight='bold', fontsize=11, pad=10)
    ax_sigma.legend(loc='upper left', frameon=True, fontsize=8, fancybox=True, framealpha=0.9)

    cbar_sigma = plt.colorbar(im_sigma, ax=ax_sigma, fraction=0.046, pad=0.04)
    cbar_sigma.set_label('Std Deviation (Ïƒ)', rotation=270, labelpad=15, fontweight='bold')

    # ========== (c) 9Dä¸ç¡®å®šæ€§æ¼”åŒ– + å‚æ•°è´¡çŒ®åº¦ ==========
    ax_evolution = fig.add_subplot(gs[0, 2])

    if len(optimizer.bo_uncertainty['posterior_at_samples']) > 0:
        posterior_data = optimizer.bo_uncertainty['posterior_at_samples']
        iters = [p['iter'] for p in posterior_data]
        mu_samples = [-p['mu'] for p in posterior_data]
        sigma_samples = [p['sigma'] for p in posterior_data]
        actual_scores = [p['actual_score'] for p in posterior_data]

        # åŒYè½´
        ax_ev1 = ax_evolution
        ax_ev2 = ax_evolution.twinx()

        # é¢„æµ‹vså®é™…
        line1 = ax_ev1.plot(iters, mu_samples, color=PALETTE['bo'], lw=2,
                            marker='o', markersize=4, label=r'9D GP Prediction ($\mu$)', zorder=10)
        line2 = ax_ev1.plot(iters, actual_scores, color=PALETTE['highlight'], lw=2,
                            marker='s', markersize=4, label='Actual Score', zorder=10)
        ax_ev1.fill_between(iters,
                            np.array(mu_samples) - np.array(sigma_samples),
                            np.array(mu_samples) + np.array(sigma_samples),
                            color=PALETTE['bo'], alpha=0.2, label=r'$\mu \pm \sigma$')

        # ä¸ç¡®å®šæ€§æ¼”åŒ–
        line3 = ax_ev2.plot(iters, sigma_samples, color='red', lw=2,
                            marker='^', markersize=4, label=r'9D Uncertainty ($\sigma$)',
                            linestyle='--', zorder=5)

        ax_ev1.set_xlabel('Iteration', fontweight='bold', fontsize=11)
        ax_ev1.set_ylabel('9D Objective Score', fontweight='bold', fontsize=11, color=PALETTE['bo'])
        ax_ev2.set_ylabel('9D Uncertainty (sigma)', fontweight='bold', fontsize=11, color='red')
        ax_ev1.tick_params(axis='y', labelcolor=PALETTE['bo'])
        ax_ev2.tick_params(axis='y', labelcolor='red')

        ax_ev1.set_title(r'(c) 9D Prediction vs Reality',
                         fontweight='bold', fontsize=11, pad=10)
        ax_ev1.grid(True, ls=':', alpha=0.3)

        # åˆå¹¶å›¾ä¾‹
        lines = line1 + line2 + line3
        labels = [l.get_label() for l in lines]
        ax_ev1.legend(lines, labels, loc='upper left', frameon=True, fontsize=8)
    else:
        ax_evolution.text(0.5, 0.5,
                          "No 9D posterior data", ha='center', va='center',
                          transform=ax_evolution.transAxes)

    fig.suptitle('9D Bayesian Optimization Global Uncertainty Reduction',
                 fontweight='bold', fontsize=14, y=0.98)

    # ä¿å­˜å›¾ç‰‡
    for fmt in ['png', 'pdf']:
        output_path = f"figures_9D/{base_path}.{fmt}"
        dpi = 300 if fmt == 'png' else None
        plt.savefig(output_path, dpi=dpi, bbox_inches='tight')
        print(f"[SAVED] Saved {fmt.upper()} format: {output_path}")

    plt.close()


# ======================== ä¸»è¿è¡Œå…¥å£ ========================
if __name__ == "__main__":
    import os

    os.makedirs("figures_9D", exist_ok=True)

    # åˆå§‹åŒ–9Dä¼˜åŒ–å™¨
    opt = NLSEOptimizer9D(x_range=(-50, 50), nx=256, t_max=12, gamma=1.5, seed=42)

    # è¿è¡Œå…¨éƒ¨ä¼˜åŒ–ç®—æ³•
    results = opt.run_all(max_iter=100)

    # ç”ŸæˆæŒ‡å®šé£æ ¼çš„å››å¼ å›¾
    plot_rogue_monster_dynamics(opt, results, base_path="9D_NLSE_Optimization_Results")
    plot_landscape_comparison(opt, results, base_path="9D_Landscape_Comparison")
    plot_raincloud_statistics(opt, results, base_path="9D_Raincloud_Statistics")
    plot_bo_uncertainty_analysis(opt, results, base_path="9D_BO_Uncertainty")

    print_separator()
    print("[SAVED] 9D Optimization Complete! (Plots saved as PNG files)")
    print_separator()
